name: Release

on:
  workflow_dispatch:  # Manual trigger from GitHub UI
    inputs:
      version:
        description: 'Version (e.g., 1.0.0)'
        required: true
        type: string
  push:
    tags:
      - 'v*'  # Triggers on version tags like v1.0.0

permissions:
  contents: write

jobs:
  # Build Python package (cross-platform, requires Python)
  build-python:
    runs-on: ubuntu-latest
    outputs:
      version: ${{ steps.version.outputs.version }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install PyTorch (CPU for export)
        run: |
          pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install onnx onnxruntime onnxscript
      
      - name: Download Model Weights
        run: |
          curl -L -o inference/marvin_small.pt https://huggingface.co/holymolyyy/marvin/resolve/main/marvin_small.pt
        shell: bash
      
      - name: Export ONNX model
        run: |
          python scripts/export_onnx.py --device cpu
      
      - name: Determine version
        id: version
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "version=${{ inputs.version }}" >> $GITHUB_OUTPUT
          else
            # Extract from tag (v1.0.0 -> 1.0.0)
            echo "version=${GITHUB_REF_NAME#v}" >> $GITHUB_OUTPUT
          fi
      
      - name: Build release package
        run: |
          python scripts/build_release.py --version ${{ steps.version.outputs.version }}
      
      - name: Upload Python package
        uses: actions/upload-artifact@v4
        with:
          name: marvin-onnx-python-v${{ steps.version.outputs.version }}
          path: dist/marvin-onnx-v${{ steps.version.outputs.version }}.zip

  # Build Windows executable (standalone, no Python needed)
  build-windows-exe:
    runs-on: windows-latest
    needs: build-python
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
          pip install -r requirements.txt
          pip install onnx onnxruntime onnxscript pyinstaller
      
      - name: Download Model Weights
        run: |
          curl -L -o inference/marvin_small.pt https://huggingface.co/holymolyyy/marvin/resolve/main/marvin_small.pt
        shell: bash
      
      - name: Export ONNX model
        run: python scripts/export_onnx.py --device cpu
        env:
          PYTHONIOENCODING: utf-8
      
      - name: Build executable
        run: python scripts/build_executable.py --version ${{ needs.build-python.outputs.version }} --no-zip
      
      - name: Create Windows archive
        run: |
          Compress-Archive -Path dist/marvin-onnx/* -DestinationPath dist/marvin-onnx-windows-v${{ needs.build-python.outputs.version }}.zip
        shell: pwsh
      
      - name: Upload Windows executable
        uses: actions/upload-artifact@v4
        with:
          name: marvin-onnx-windows-v${{ needs.build-python.outputs.version }}
          path: dist/marvin-onnx-windows-v${{ needs.build-python.outputs.version }}.zip

  # Build Linux executable (standalone, no Python needed)
  build-linux-exe:
    runs-on: ubuntu-latest
    needs: build-python
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
          pip install -r requirements.txt
          pip install onnx onnxruntime onnxscript pyinstaller
      
      - name: Download Model Weights
        run: |
          curl -L -o inference/marvin_small.pt https://huggingface.co/holymolyyy/marvin/resolve/main/marvin_small.pt
        shell: bash
      
      - name: Export ONNX model
        run: python scripts/export_onnx.py --device cpu
      
      - name: Build executable
        run: python scripts/build_executable.py --version ${{ needs.build-python.outputs.version }} --no-zip
      
      - name: Create Linux archive
        run: |
          cd dist && tar -czvf marvin-onnx-linux-v${{ needs.build-python.outputs.version }}.tar.gz marvin-onnx/
      
      - name: Upload Linux executable
        uses: actions/upload-artifact@v4
        with:
          name: marvin-onnx-linux-v${{ needs.build-python.outputs.version }}
          path: dist/marvin-onnx-linux-v${{ needs.build-python.outputs.version }}.tar.gz

  # Create GitHub Release
  release:
    runs-on: ubuntu-latest
    needs: [build-python, build-windows-exe, build-linux-exe]
    if: startsWith(github.ref, 'refs/tags/v')
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
      
      - name: List artifacts
        run: find artifacts -type f
      
      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          files: |
            artifacts/**/*.zip
            artifacts/**/*.tar.gz
          body: |
            ## Marvin Chess AI v${{ needs.build-python.outputs.version }}
            
            A human-like chess engine that mimics play styles across skill levels (1200-2500 Elo).
            
            ### Downloads
            
            | Platform | File | Requirements |
            |----------|------|--------------|
            | **Windows (standalone)** | `marvin-onnx-windows-v${{ needs.build-python.outputs.version }}.zip` | None! Just extract and run |
            | **Linux (standalone)** | `marvin-onnx-linux-v${{ needs.build-python.outputs.version }}.tar.gz` | None! Just extract and run |
            | **Cross-platform (Python)** | `marvin-onnx-python-v${{ needs.build-python.outputs.version }}.zip` | Python 3.10+ |
            
            ### Quick Start (Standalone)
            
            1. Download the file for your platform
            2. Extract to a folder
            3. Configure your chess GUI to use:
               - Windows: `marvin-onnx.exe`
               - Linux: `./marvin-onnx`
            
            ### Quick Start (Python)
            
            1. Download the Python package
            2. Extract and run: `pip install -r requirements.txt`
            3. Run: `python uci_onnx.py`
            
            ### UCI Options
            
            | Option | Default | Description |
            |--------|---------|-------------|
            | EngineElo | 1900 | Engine's playing strength (1200-2500) |
            | Temperature | 0.35 | Move randomness |
            | OpeningTemperature | 1.2 | Randomness in opening phase |
            | OpeningLength | 10 | Plies considered "opening" |
            
            ### Links
            
            - [Documentation](https://github.com/zingalorp/marvin-chess)
            - [Play on Lichess](https://lichess.org/@/marvin-2000)
          draft: false
          prerelease: false
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
